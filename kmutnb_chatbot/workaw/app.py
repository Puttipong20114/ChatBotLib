import os
import google.generativeai as genai
import pandas as pd
import streamlit as st
from prompt import PROMPT_WORKAW
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from document_reader import get_kmutnb_summary

# ‚úÖ ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ç‡∏≠: ‡πÑ‡∏°‡πà‡πÅ‡∏ï‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ
genai.configure(api_key="AIzaSyB04pWtDwUQZV325jJ_3XtF2-9CXbi1O74")

# ----------------- CONFIG -----------------
generation_config = {
    "temperature": 0.1,
    "top_p": 0.95,
    "top_k": 64,
    # "max_output_tokens": 8192,
    "max_output_tokens": 512,  # ‡∏•‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô rate limit ‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡πÑ‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
    "response_mime_type": "text/plain",
    "candidate_count": 1,      # ‡πÉ‡∏´‡πâ‡∏£‡∏∏‡πà‡∏ô‡∏ï‡∏≠‡∏ö‡∏°‡∏≤‡∏ä‡πâ‡∏≠‡∏¢‡∏™‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
}

SAFETY_SETTINGS = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE
}

# ‡∏™‡∏£‡πâ‡∏≤‡∏á model ‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
@st.cache_resource(show_spinner=False)
def get_model():
    return genai.GenerativeModel(
        model_name="gemini-1.5-flash",
        safety_settings=SAFETY_SETTINGS,
        generation_config=generation_config,
        system_instruction=PROMPT_WORKAW
    )

model = get_model()

# ----------------- FILE PATH MANAGEMENT -----------------
def find_dataset_file():
    """
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå dataset ‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ó‡∏µ‡πà ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ work ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô local ‡πÅ‡∏•‡∏∞ deployed environment
    """
    possible_paths = [
        # Path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö local development
        "DataSetLibraly.pdf",
        "./DataSetLibraly.pdf",
        os.path.join(os.path.dirname(__file__), "DataSetLibraly.pdf"),
        
        # Path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö deployed environment (Streamlit Cloud, Heroku, etc.)
        os.path.join(os.getcwd(), "DataSetLibraly.pdf"),
        "/app/DataSetLibraly.pdf",  # Heroku
        "/mount/src/DataSetLibraly.pdf",  # Streamlit Cloud
        
        # Path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö subfolder
        os.path.join("data", "DataSetLibraly.pdf"),
        os.path.join("assets", "DataSetLibraly.pdf"),
        os.path.join("documents", "DataSetLibraly.pdf"),
        
        # Alternative names
        "dataset_library.pdf",
        "DataSetLibrary.pdf",  # ‡πÅ‡∏Å‡πâ‡∏Å‡∏≤‡∏£‡∏™‡∏∞‡∏Å‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ú‡∏¥‡∏î
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    
    return None

def get_dataset_path():
    """
    ‡∏´‡∏≤ path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå dataset ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏™‡∏î‡∏á debug info
    """
    # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
    found_path = find_dataset_file()
    
    if found_path:
        return found_path
    
    # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÅ‡∏™‡∏î‡∏á debug info
    st.sidebar.write("üîç **Debug Info:**")
    st.sidebar.write(f"Current working directory: `{os.getcwd()}`")
    st.sidebar.write(f"Script directory: `{os.path.dirname(__file__)}`")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
    try:
        files = os.listdir(os.getcwd())
        pdf_files = [f for f in files if f.endswith('.pdf')]
        st.sidebar.write(f"PDF files found: {pdf_files}")
        st.sidebar.write(f"All files in current dir: {files[:10]}...")  # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà 10 ‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å
    except Exception as e:
        st.sidebar.write(f"Error listing files: {e}")
    
    return None

# ----------------- IO & CACHE -----------------
# ‡∏≠‡πà‡∏≤‡∏ô/‡∏™‡∏£‡∏∏‡∏õ PDF ‡πÅ‡∏•‡πâ‡∏ß cache ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ‡∏Å‡∏±‡∏ô I/O ‡∏´‡∏ô‡∏±‡∏Å ‡πÜ ‡∏ï‡∏≠‡∏ô rerun
@st.cache_data(show_spinner=True)
def load_kmutnb_summary(path: str) -> str:
    """Load ‡πÅ‡∏•‡∏∞ cache ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å PDF"""
    try:
        return get_kmutnb_summary(path)
    except Exception as e:
        return f"Error loading PDF: {str(e)}"

# ----------------- UPLOAD FALLBACK -----------------
def handle_file_upload():
    """
    ‡πÉ‡∏´‡πâ user ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏á‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠
    """
    st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå DataSetLibraly.pdf ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")
    st.info("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå dataset ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì")
    
    uploaded_file = st.file_uploader(
        "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF Dataset",
        type=['pdf'],
        help="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå DataSetLibraly.pdf ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå PDF ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î KMUTNB"
    )
    
    if uploaded_file is not None:
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
        temp_path = f"temp_{uploaded_file.name}"
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        st.success(f"‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå {uploaded_file.name} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
        return temp_path
    
    return None

# ----------------- UI -----------------
def clear_history():
    st.session_state["messages"] = [
        {"role": "model", "content": "KMUTNB Library Chatbot ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö KMUTNB Library ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏î‡∏Ñ‡∏£‡∏±‡∏ö"}
    ]
    # ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡πÅ‡∏ä‡∏ó‡πÄ‡∏ã‡∏™‡∏ä‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏µ‡∏≠‡∏¥‡∏ô‡πÄ‡∏à‡πá‡∏Å‡∏ï‡πå context ‡πÉ‡∏´‡∏°‡πà
    st.session_state.pop("chat_session", None)
    st.rerun()

with st.sidebar:
    if st.button("Clear History"):
        clear_history()
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÑ‡∏ü‡∏•‡πå
    st.markdown("---")
    st.subheader("üìÅ File Status")

st.title("üí¨ KMUTNB Library Chatbot ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {
            "role": "model",
            "content": "KMUTNB Library Chatbot ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö KMUTNB Library ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏î‡∏Ñ‡∏£‡∏±‡∏ö",
        }
    ]

# ----------------- LOAD DATASET WITH FLEXIBLE PATH -----------------
file_path = get_dataset_path()

if file_path is None:
    # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ user ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏á
    file_path = handle_file_upload()

if file_path is None:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå dataset ‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á")
    st.stop()

# ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
with st.sidebar:
    st.success(f"‚úÖ Using file: `{os.path.basename(file_path)}`")
    st.caption(f"Full path: `{file_path}`")

try:
    file_content = load_kmutnb_summary(file_path)
    if isinstance(file_content, str) and file_content.startswith("Error"):
        st.error(file_content)
        st.info("üí° ‡∏•‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå PDF ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà")
        st.stop()
    else:
        with st.sidebar:
            st.info(f"üìÑ Content loaded: {len(file_content)} characters")
except Exception as e:
    st.error(f"Error reading file: {e}")
    st.stop()

# ----------------- CREATE / REUSE CHAT SESSION -----------------
# ‡∏¢‡∏±‡∏î context ‡∏à‡∏≤‡∏Å PDF ‡πÄ‡∏Ç‡πâ‡∏≤ history ‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ä‡πâ session ‡πÄ‡∏î‡∏¥‡∏°‡∏ï‡πà‡∏≠ ‡∏¢‡πà‡∏ô‡πÄ‡∏ß‡∏•‡∏≤!
def ensure_chat_session():
    if "chat_session" not in st.session_state:
        # ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö history ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: system ‡πÄ‡∏õ‡∏¥‡∏î‡∏ö‡∏ó + user ‡πÉ‡∏™‡πà‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å PDF ‡πÄ‡∏õ‡πá‡∏ô context
        base_history = [
            {
                "role": "model",
                "parts": [{"text": "KMUTNB Library Chatbot ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏ö‡πÑ‡∏ß‡πâ"}],
            },
            {
                "role": "user",
                "parts": [{
                    "text": (
                        "‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• KMUTN Library ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ "
                        "(‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡πà‡∏≠‡∏á‡∏à‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î):\n\n"
                        + file_content
                    )
                }],
            },
        ]
        st.session_state["chat_session"] = model.start_chat(history=base_history)

ensure_chat_session()

# ----------------- RENDER HISTORY (‡πÇ‡∏ä‡∏ß‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡πâ‡∏≤‡∏¢ ‡πÜ ‡πÉ‡∏´‡πâ‡πÑ‡∏ß) -----------------
def render_messages(limit_last:int = 20):
    for msg in st.session_state["messages"][-limit_last:]:
        st.chat_message(msg["role"]).write(msg["content"])

render_messages()

# ----------------- HANDLE INPUT -----------------
prompt = st.chat_input(placeholder="‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö KMUTNB Library ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‚ú®")

def trim_history(max_pairs:int = 8):
    """
    ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß history ‡πÉ‡∏ô UI (‡πÅ‡∏•‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏£‡∏∏‡∏õ)
    ‡πÄ‡∏Å‡πá‡∏ö‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏π‡πà‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡πâ‡∏≤‡∏¢ ‡πÜ ‡∏•‡∏î token ‚Üí ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
    """
    msgs = st.session_state["messages"]
    # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡πâ‡∏≤‡∏¢ ‡πÜ
    if len(msgs) > (2 * max_pairs + 1):  # model msg ‡πÅ‡∏£‡∏Å + n*2 (user/model)
        st.session_state["messages"] = msgs[-(2 * max_pairs + 1):]

def generate_response(user_text: str):
    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï UI history
    st.session_state["messages"].append({"role": "user", "content": user_text})
    st.chat_message("user").write(user_text)

    # ‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì
    if user_text.lower().startswith("add") or user_text.lower().endswith("add"):
        reply = "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ñ‡∏£‡∏±‡∏ö"
        st.session_state["messages"].append({"role": "model", "content": reply})
        st.chat_message("model").write(reply)
        trim_history()
        return

    # ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏ï‡∏£‡∏µ‡∏°‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö (latency ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏ö‡∏ö non-stream)
    placeholder = st.chat_message("model")
    stream_box = placeholder.empty()
    collected = []

    try:
        for chunk in st.session_state["chat_session"].send_message(user_text, stream=True):
            piece = getattr(chunk, "text", None)
            if piece:
                collected.append(piece)
                stream_box.write("".join(collected))
        final_text = "".join(collected).strip() or "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ"
    except Exception as e:
        final_text = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö: {e}"

    st.session_state["messages"].append({"role": "model", "content": final_text})
    trim_history()

if prompt:
    generate_response(prompt)