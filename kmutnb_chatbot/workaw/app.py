import os
import google.generativeai as genai
import pandas as pd
import streamlit as st
from prompt import PROMPT_WORKAW
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from document_reader import get_kmutnb_summary
import tempfile

# ‚úÖ ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ç‡∏≠: ‡πÑ‡∏°‡πà‡πÅ‡∏ï‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ
genai.configure(api_key="AIzaSyD9ycgboJDlkj-JoyRJy8QKaAagEq3TAEQ")

# ----------------- CONFIG -----------------
generation_config = {
    "temperature": 0.1,
    "top_p": 0.95,
    "top_k": 64,
    # "max_output_tokens": 8192,
    "max_output_tokens": 512,  # ‡∏•‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô rate limit ‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡πÑ‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
    "response_mime_type": "text/plain",
    "candidate_count": 1,      # ‡πÉ‡∏´‡πâ‡∏£‡∏∏‡πà‡∏ô‡∏ï‡∏≠‡∏ö‡∏°‡∏≤‡∏ä‡πâ‡∏≠‡∏¢‡∏™‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
}

SAFETY_SETTINGS = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE
}

# ‡∏™‡∏£‡πâ‡∏≤‡∏á model ‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
@st.cache_resource(show_spinner=False)
def get_model():
    return genai.GenerativeModel(
        model_name="gemini-1.5-flash",
        safety_settings=SAFETY_SETTINGS,
        generation_config=generation_config,
        system_instruction=PROMPT_WORKAW
    )

model = get_model()

# ----------------- IO & CACHE -----------------
# ‡∏≠‡πà‡∏≤‡∏ô/‡∏™‡∏£‡∏∏‡∏õ PDF ‡πÅ‡∏•‡πâ‡∏ß cache ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ‡∏Å‡∏±‡∏ô I/O ‡∏´‡∏ô‡∏±‡∏Å ‡πÜ ‡∏ï‡∏≠‡∏ô rerun
@st.cache_data(show_spinner=True)
def load_kmutnb_summary_from_bytes(file_bytes: bytes, filename: str) -> str:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á temporary file ‡∏à‡∏≤‡∏Å uploaded bytes ‡πÅ‡∏•‡πâ‡∏ß‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•"""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(file_bytes)
            tmp_path = tmp_file.name
        
        # ‡πÉ‡∏ä‡πâ temporary file path
        result = get_kmutnb_summary(tmp_path)
        
        # ‡∏•‡∏ö temporary file
        os.unlink(tmp_path)
        
        return result
    except Exception as e:
        return f"Error processing file: {str(e)}"

# Alternative: ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô repository (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ default file)
@st.cache_data(show_spinner=True)
def load_default_kmutnb_summary() -> str:
    """‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå default ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô project directory"""
    # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö script ‡∏´‡∏£‡∏∑‡∏≠ subfolder
    possible_paths = [
        "DataSetLibraly.pdf",  # ‡πÉ‡∏ô root folder
        "data/DataSetLibraly.pdf",  # ‡πÉ‡∏ô data folder
        "workaw/DataSetLibraly.pdf",  # ‡πÉ‡∏ô workaw folder
        os.path.join(os.path.dirname(__file__), "DataSetLibraly.pdf"),  # same dir as script
        os.path.join(os.path.dirname(__file__), "data", "DataSetLibraly.pdf"),
        os.path.join(os.path.dirname(__file__), "workaw", "DataSetLibraly.pdf"),
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return get_kmutnb_summary(path)
    
    return "Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå DataSetLibraly.pdf ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå"

# ----------------- UI -----------------
def clear_history():
    st.session_state["messages"] = [
        {"role": "model", "content": "KMUTNB Library Chatbot ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö KMUTNB Library ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏î‡∏Ñ‡∏£‡∏±‡∏ö"}
    ]
    # ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡πÅ‡∏ä‡∏ó‡πÄ‡∏ã‡∏™‡∏ä‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏µ‡∏≠‡∏¥‡∏ô‡πÄ‡∏à‡πá‡∏Å‡∏ï‡πå context ‡πÉ‡∏´‡∏°‡πà
    st.session_state.pop("chat_session", None)
    st.rerun()

# ----------------- SIDEBAR -----------------
with st.sidebar:
    st.header("üìÅ File Management")
    
    # File uploader
    uploaded_file = st.file_uploader(
        "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• KMUTNB Library)",
        type=['pdf'],
        help="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• KMUTNB Library"
    )
    
    use_default = st.checkbox(
        "‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå default ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö", 
        value=True if not uploaded_file else False,
        help="‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå DataSetLibraly.pdf ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"
    )
    
    st.divider()
    
    if st.button("Clear History", use_container_width=True):
        clear_history()
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÑ‡∏ü‡∏•‡πå
    st.subheader("üìä File Status")
    if uploaded_file:
        st.success(f"‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î: {uploaded_file.name}")
        st.info(f"üìä ‡∏Ç‡∏ô‡∏≤‡∏î: {uploaded_file.size:,} bytes")
    elif use_default:
        st.info("üîÑ ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå default ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")
    else:
        st.warning("‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå")

# ----------------- MAIN UI -----------------
st.title("üí¨ KMUTNB Library Chatbot")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {
            "role": "model",
            "content": "KMUTNB Library Chatbot ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö KMUTNB Library ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏î‡∏Ñ‡∏£‡∏±‡∏ö",
        }
    ]

# ----------------- LOAD DATASET -----------------
file_content = None

try:
    if uploaded_file:
        # ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
        st.info("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î...")
        file_bytes = uploaded_file.read()
        file_content = load_kmutnb_summary_from_bytes(file_bytes, uploaded_file.name)
    elif use_default:
        # ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå default
        st.info("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå default...")
        file_content = load_default_kmutnb_summary()
    
    if file_content and file_content.startswith("Error:"):
        st.error(file_content)
        st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå default ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")
        file_content = None
    elif file_content:
        st.success("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
        
except Exception as e:
    st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå: {e}")
    file_content = None

# ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
if not file_content:
    st.stop()

# ----------------- CREATE / REUSE CHAT SESSION -----------------
def ensure_chat_session():
    if "chat_session" not in st.session_state or not file_content:
        # ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö history ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: system ‡πÄ‡∏õ‡∏¥‡∏î‡∏ö‡∏ó + user ‡πÉ‡∏™‡πà‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å PDF ‡πÄ‡∏õ‡πá‡∏ô context
        base_history = [
            {
                "role": "model",
                "parts": [{"text": "KMUTNB Library Chatbot ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏ö‡πÑ‡∏ß‡πâ"}],
            },
            {
                "role": "user",
                "parts": [{
                    "text": (
                        "‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• KMUTN Library ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ "
                        "(‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡πà‡∏≠‡∏á‡∏à‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î):\n\n"
                        + file_content
                    )
                }],
            },
        ]
        st.session_state["chat_session"] = model.start_chat(history=base_history)

ensure_chat_session()

# ----------------- RENDER HISTORY (‡πÇ‡∏ä‡∏ß‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡πâ‡∏≤‡∏¢ ‡πÜ ‡πÉ‡∏´‡πâ‡πÑ‡∏ß) -----------------
def render_messages(limit_last: int = 20):
    for msg in st.session_state["messages"][-limit_last:]:
        st.chat_message(msg["role"]).write(msg["content"])

render_messages()

# ----------------- HANDLE INPUT -----------------
prompt = st.chat_input(
    placeholder="‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö KMUTNB Library ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‚ú®",
    disabled=not file_content
)

def trim_history(max_pairs: int = 8):
    """
    ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß history ‡πÉ‡∏ô UI (‡πÅ‡∏•‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏£‡∏∏‡∏õ)
    ‡πÄ‡∏Å‡πá‡∏ö‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏π‡πà‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡πâ‡∏≤‡∏¢ ‡πÜ ‡∏•‡∏î token ‚Üí ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
    """
    msgs = st.session_state["messages"]
    # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡πâ‡∏≤‡∏¢ ‡πÜ
    if len(msgs) > (2 * max_pairs + 1):  # model msg ‡πÅ‡∏£‡∏Å + n*2 (user/model)
        st.session_state["messages"] = msgs[-(2 * max_pairs + 1):]

def generate_response(user_text: str):
    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï UI history
    st.session_state["messages"].append({"role": "user", "content": user_text})
    st.chat_message("user").write(user_text)

    # ‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì
    if user_text.lower().startswith("add") or user_text.lower().endswith("add"):
        reply = "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ñ‡∏£‡∏±‡∏ö"
        st.session_state["messages"].append({"role": "model", "content": reply})
        st.chat_message("model").write(reply)
        trim_history()
        return

    # ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏ï‡∏£‡∏µ‡∏°‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö (latency ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏ö‡∏ö non-stream)
    placeholder = st.chat_message("model")
    stream_box = placeholder.empty()
    collected = []

    try:
        for chunk in st.session_state["chat_session"].send_message(user_text, stream=True):
            piece = getattr(chunk, "text", None)
            if piece:
                collected.append(piece)
                stream_box.write("".join(collected))
        final_text = "".join(collected).strip() or "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ"
    except Exception as e:
        final_text = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö: {e}"

    st.session_state["messages"].append({"role": "model", "content": final_text})
    trim_history()

if prompt and file_content:
    generate_response(prompt)